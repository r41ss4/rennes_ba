


# Import libs
import pandas as pd
import numpy as np





# Read database 1 
data_n1 = pd.read_csv("https://raw.githubusercontent.com/r41ss4/rennes_ba/refs/heads/main/data/raw/data_n1.csv")


# General data_n1 view
data_n1.head(10)


# Review data_n1 information 
data_n1.shape


# Review data_n1 general information
data_n1.info()


# Review data_n1 columns 
data_n1.columns


# Review the data and how many rows have missing information in each columns
data_n1.isna().sum()





# Make a copy of clean_datan1 to clean
clean_datan1 = data_n1


# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Check duplicated data
clean_datan1.drop_duplicates()


# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Complete missing values of 'duration'
# Identify values of duration
clean_datan1['duration'].unique()


# Eliminate ' min' in all rows of duration
clean_datan1['duration'] = clean_datan1['duration'].str.replace(' min', '')
# Review changes 
clean_datan1.head(10)


# Fill NaN values with 0
clean_datan1['duration'] = clean_datan1['duration'].fillna(0)


# Turn duration into int
clean_datan1['duration'] = clean_datan1['duration'].astype(float)


# Calculate the mean of the non-zero values
mean_duration = clean_datan1[clean_datan1['duration'] != 0]['duration'].mean()

# Replace 0 values with the mean duration
clean_datan1.loc[clean_datan1['duration'] == 0, 'duration'] = mean_duration


# Change 'duration' name for 'duration_min'
clean_datan1 = clean_datan1.rename(columns={'duration': 'duration_min'})
# Review changes 
clean_datan1.head(10)


# Review general information
clean_datan1.info()


# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Fill missing values in genre with the mode
clean_datan1['genre'] = clean_datan1['genre'].fillna(clean_datan1['genre'].mode()[0])
# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Complete missing values of 'voters'
# Eliminate ' min' in all rows of duration
clean_datan1['votes'] = clean_datan1['votes'].str.replace(',', '')
# Review changes 
clean_datan1.head(10)


# Fill NaN values with 0
clean_datan1['votes'] = clean_datan1['votes'].fillna(0)
# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Turn votes into float
clean_datan1['votes'] = clean_datan1['votes'].astype(float)


# Calculate the mean of the non-zero values
mean_votes = clean_datan1[clean_datan1['votes'] != 0]['votes'].mean()

# Replace 0 values with the mean duration
clean_datan1.loc[clean_datan1['votes'] == 0, 'votes'] = mean_votes


# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Remove the opening parenthesis '('
clean_datan1['year'] = clean_datan1['year'].str.replace(r'\(', '', regex=True)
# Review changes 
clean_datan1.head(10)


# Remove everything from '–' onwards, including '–'
clean_datan1['year'] = clean_datan1['year'].str.replace(r'–.*', '', regex=True)
# Review changes 
clean_datan1.head(10)


# Remove everything from '–' onwards, including '–'
clean_datan1['year'] = clean_datan1['year'].str.replace(r'\)', '', regex=True)
# Review changes 
clean_datan1.head(10)


# Remove any non-numeric characters
clean_datan1['year'] = clean_datan1['year'].str.extract(r'(\d{4})')[0]


# Fill NaN values with 0
clean_datan1['year'] = clean_datan1['year'].fillna(0)
# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Convert the 'year' column to integers
clean_datan1['year'] = clean_datan1['year'].astype(int)


# Calculate the mean of the non-zero values
mean_votes = clean_datan1[clean_datan1['votes'] != 0]['votes'].mean()

# Replace 0 values with the mean duration
clean_datan1.loc[clean_datan1['votes'] == 0, 'votes'] = mean_votes


# Review general information
clean_datan1.info()


# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Fill certificate with the mode, as it is an object
clean_datan1['certificate'] = clean_datan1['certificate'].fillna(clean_datan1['certificate'].mode()[0])
# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Fill the certificate with the mean, as it is an integer
clean_datan1['rating'] = clean_datan1['rating'].fillna(clean_datan1['rating'].mean())
# Review the data and how many rows have missing information in each columns
clean_datan1.isna().sum()


# Save the cleaned dataset 1 ('clean_datan1')
clean_datan1.to_csv('clean_datan1.csv', index=False)





# Read database 2 
data_n2 = pd.read_csv("data/raw/data_n2.csv")


# Read the file with ISO-8859-1 encoding
data_n2 = pd.read_csv("data_n2.csv", encoding='ISO-8859-1')


# General data_n2 view
data_n2.head(10)


# Review data_n2 information 
data_n2.shape


# Review data_n2 general information
data_n2.info()


# Review data_n2 columns 
data_n2.columns


# Review the data and how many rows have missing information in each columns
data_n2.isna().sum()


# Make a copy of clean_datan2 to clean
clean_datan2 = data_n2


# Review the data and how many rows have missing information in each columns
clean_datan2.isna().sum()


# Check duplicated data
datan2_dup = clean_datan2[clean_datan2.duplicated()]
datan2_dup


# Delete duplicate rows, keeping the first occurrence
clean_datan2 = clean_datan2.drop_duplicates()
clean_datan2


# Fill 'ratingLevel' with the mode
clean_datan2['ratingLevel'] = clean_datan2['ratingLevel'].fillna(clean_datan2['ratingLevel'].mode()[0])
# Review the data and how many rows have missing information in each columns
clean_datan2.isna().sum()


# Fill 'user rating score' with the mode
clean_datan2['user rating score'] = clean_datan2['user rating score'].fillna(clean_datan2['user rating score'].mean())
# Review the data and how many rows have missing information in each columns
clean_datan2.isna().sum()


# Save the cleaned dataset 2 ('clean_datan2')
clean_datan2.to_csv('clean_datan2.csv', index=False)





# Read database 3 
data_n3 = pd.read_csv("data_n3.csv")


# General data_n3 view
data_n3.head(10)


# Review data_n3 information 
data_n3.shape


# Review data_n3 general information
data_n3.info()


# Review data_n3 columns 
data_n3.columns


# Review the data and how many rows have missing information in each columns
data_n3.isna().sum()


# Check duplicated data
datan3_dup = data_n3[data_n3.duplicated()]
datan3_dup


# Delete duplicate rows, keeping the first occurrence
data_n3 = data_n3.drop_duplicates()
data_n3





# Make a copy called dirty_datan3
dirty_datan3 = data_n3


# Add redundant columns 'titel2' with changed type 
dirty_datan3['title2'] = dirty_datan3['title'].astype(str)


# Change 'year' column to strings
dirty_datan3['year'] = dirty_datan3['year'].astype(str)


# Introduce duplicates to dirty_datan3
dirty_datan3 = pd.concat([dirty_datan3, dirty_datan3.sample(frac=0.1)])


# Count the number of duplicate rows
dirty_datan3.duplicated().sum()


# Missnamed two columns
dirty_datan3 = dirty_datan3.rename(columns={'title': 'tite', 'language': 'lenguge'})


# Review changes in dirty_datan3
dirty_datan3.head(5)





# Make a copy of dirty_datan3 to clean
clean_datan3 = dirty_datan3


# Remove redundant column Duration
clean_datan3 = clean_datan3.drop(columns=['title2'])


# Change 'year' column to integer
clean_datan3['year'] = clean_datan3['year'].astype('datetime64[ns]')


# Drop duplicates from clean_datan3
clean_datan3.drop_duplicates()


# Count the number of duplicate rows
clean_datan3.duplicated().sum()


# Missnamed two columns
clean_datan3 = clean_datan3.rename(columns={'tite': 'title', 'lenguge': 'language'})


# Review changes in clean_datan3
clean_datan3.head(5)


# Review the data and how many rows have missing information in each columns
clean_datan3.isna().sum()


# Save the cleaned dataset 3 ('clean_datan3')
clean_datan3.to_csv('clean_datan3.csv', index=False)





data_n4= pd.read_csv("data_n4.csv")


data_n4.head()


data_n4.shape


data_n4.info()


data_n4.columns





# Make a copy of clean_datan4 to clean
clean_datan4 = data_n4


clean_datan4.drop_duplicates()


clean_datan4.isna().sum()


# For 'description' we'll change it to 'No description available' to avoid future mistakes
clean_datan4['description'] = clean_datan4['description'].fillna('No description available')


clean_datan4.isna().sum()


#For numeric columns, the median will be used so that it doesn't change the important measures 
num_cols = ['imdb_score', 'imdb_votes', 'tmdb_popularity', 'tmdb_score']
for col in num_cols:
    clean_datan4[col] = clean_datan4[col].fillna(clean_datan4[col].median())


clean_datan4.isna().sum()


# 'Seasons' will be cleaned by assuming a 0 for movies or no more seasons
clean_datan4['seasons'] = clean_datan4['seasons'].fillna(0).astype(int)


clean_datan4.isna().sum()


# For cleaning 'age_certification' the blank rows will be filled with 'Unknown'
clean_datan4['age_certification'] = clean_datan4['age_certification'].fillna('Unknown')


clean_datan4.isna().sum()


# It is important to convert the lists saved as strings as real lists to facilitate further analysis
columns = ['genres', 'production_countries']
for col in columns:
    clean_datan4[col] = clean_datan4[col].apply(lambda x: eval(x) if isinstance(x, str) else x)


clean_datan4.isna().sum()





# In order to normalize the data, we'll limite the release year to reasonable years (from 1900-2024)
clean_datan4 = clean_datan4[(clean_datan4['release_year'] >= 1900) & (clean_datan4['release_year'] <= 2024)]


clean_datan4


# We're also limiting the values that are out of the range in 'runtime'
clean_datan4['runtime'] = clean_datan4['runtime'].apply(lambda x: x if x > 0 and x < 500 else None)
clean_datan4['runtime'] = clean_datan4['runtime'].fillna(clean_datan4['runtime'].median())


clean_datan4


#And just to be sure, we're limiting the values out of range in scores
clean_datan4['imdb_score'] = clean_datan4['imdb_score'].apply(lambda x: x if 0 <= x <= 10 else None)
clean_datan4['tmdb_score'] = clean_datan4['tmdb_score'].apply(lambda x: x if 0 <= x <= 10 else None)


clean_datan4


 # It is important to also standarize the strip & lowercase formats
clean_datan4['title'] = clean_datan4['title'].str.strip()
clean_datan4['type'] = clean_datan4['type'].str.strip().str.upper()
clean_datan4['age_certification'] = clean_datan4['age_certification'].str.strip()





#In this case a new column will be created to calculate the age of the movie based on the released year and the actual year. 
#This could be useful for a next analysis
from datetime import datetime
current_year = datetime.now().year
clean_datan4['title_age'] = current_year - clean_datan4['release_year']


clean_datan4


# Save the cleaned dataset 4 ('clean_datan4')
clean_datan4.to_csv('clean_datan4.csv', index=False)



