


# Imoprt libs
import pandas as pd
import numpy as np
import seaborn as sn
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report, precision_recall_curve, roc_curve, auc


# Read database 1 
df = pd.read_csv("https://raw.githubusercontent.com/r41ss4/rennes_ba/refs/heads/main/data/merged/merged_data.csv")











# Define features and rating as the target variable
Xr = df.drop(columns=['rating'])  
yr = df['rating']


# Split the data into training and testing sets
X_trainr, X_testr, y_trainr, y_testr = train_test_split(Xr, yr, test_size=0.2, random_state=42)





# Identify categorical columns
cat_cols = Xr.select_dtypes(include=['object']).columns


# Preprocessing for numerical data
num_transformer = SimpleImputer(strategy='mean')


# Preprocessing for categorical data
cat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])


# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', num_transformer, Xr.select_dtypes(exclude=['object']).columns),
        ('cat', cat_transformer, cat_cols)
    ])


# Convert continuous target variable to discrete classes for Logistic Regression
# Example: Convert ratings to binary classes (0 and 1)
thresholdlog = yr.median()
y_classlog = (yr >= thresholdlog).astype(int)


# Identify categorical columns
logcat_cols = Xr.select_dtypes(include=['object']).columns


# Preprocessing for numerical data
lognum_transformer = SimpleImputer(strategy='mean')


# Preprocessing for categorical data
logcat_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])


# Bundle preprocessing for numerical and categorical data
logpreprocessor = ColumnTransformer(
    transformers=[
        ('num', lognum_transformer, Xr.select_dtypes(exclude=['object']).columns),
        ('cat', logcat_transformer, logcat_cols)
    ])


# Split the data into training and testing sets for Logistic Regression
X_train_logreg, X_test_logreg, y_train_logreg, y_test_logreg = train_test_split(Xr, y_classlog, test_size=0.2, random_state=42)





# Filter out rows where 'type' is 'Unknown'
df2 = df[df['type'] != 'Unknown']


# Convert numeric data into numeric data that will be able to handle it
# In our dataset Show(1) and Series(2) 
df2.type[df2.type == 'Show'] = 1
df2.type[df2.type == 'Movie'] = 2
df2.head()


# Define features and rating as the target variable
Xlr = df2[['type']] 
ylr = df2['rating'] 


# Split the data into training and testing sets in simple regression
X_trainlr, X_testlr, y_trainlr, y_testlr = train_test_split(Xlr, ylr, test_size=0.2, random_state=42)








# Define the model
rf_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', RandomForestRegressor(n_estimators=100, random_state=42))
])


# Train the random forest model
rf_model.fit(X_trainr, y_trainr)





# Define the model for Linear Regression
lr_model = Pipeline(steps=[
    ('model', LinearRegression())
])


# Train the linear regression model
lr_model.fit(X_trainlr, y_trainlr)





# Multiple Linear Regression
mlr_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LinearRegression())
])


# Train the Linear Regression model
mlr_model.fit(X_trainr, y_trainr)





# Logistic Regression
logreg_model = Pipeline(steps=[
    ('preprocessor', logpreprocessor),
    ('model', LogisticRegression(max_iter=1000))
])


# Train the Linear Regression model
logreg_model.fit(X_train_logreg, y_train_logreg)








# Make predictions
rf_predictions = rf_model.predict(X_testr)


# Evaluate the model
rf_mse = mean_squared_error(y_testr, rf_predictions)
rf_r2 = r2_score(y_testr, rf_predictions)


# Review results
print(f'Random Forest MSE: {rf_mse}')
print(f'Random Forest R2: {rf_r2}')





# Make predictions
lr_predictions = lr_model.predict(X_testlr)


# Evaluate the model
lr_mse = mean_squared_error(y_testlr, lr_predictions)
lr_r2 = r2_score(y_testlr, lr_predictions)


# Review results
print(f'Linear Regression MSE: {lr_mse}')
print(f'Linear Regression R2: {lr_r2}')





# Make predictions
mlr_predictions = mlr_model.predict(X_testr)


# Evaluate the model
mlr_mse = mean_squared_error(y_testr, mlr_predictions)
mlr_r2 = r2_score(y_testr, mlr_predictions)


# Review results
print(f'Multiple Linear Regression MSE: {mlr_mse}')
print(f'Multiple Linear Regression R2: {mlr_r2}')





# Make predictions for Logistic Regression
logreg_predictions = logreg_model.predict(X_test_logreg)


# Evaluate the model
logreg_mse = mean_squared_error(y_test_logreg, logreg_predictions)
logreg_r2 = r2_score(y_test_logreg, logreg_predictions)


# Review results
print(f'Logistic Regression MSE: {logreg_mse}')
print(f'Logistic Regression R2: {logreg_r2}')








# Plotting Random Forest predictions vs actual values
plt.figure(figsize=(10, 5))
plt.scatter(y_testr, rf_predictions, color='blue', label='Random Forest Predictions')
plt.plot([y_testr.min(), y_testr.max()], [y_testr.min(), y_testr.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Random Forest: Actual vs Predicted')
plt.legend()
plt.show()


# Residual plot for Linear Regression
rf_residuals = y_testr - rf_predictions
plt.figure(figsize=(10, 5))
plt.scatter(rf_predictions, rf_residuals, color='blue', label='Random Forest Residuals')
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted')
plt.ylabel('Residuals')
plt.title('Random Forest Residual Plot')
plt.legend()
plt.show()





# Plotting Linear Regression predictions vs actual values
plt.figure(figsize=(10, 5))
plt.scatter(y_testr, mlr_predictions, color='red', label='Multiple Linear Regression Predictions')
plt.plot([y_testr.min(), y_testr.max()], [y_testr.min(), y_testr.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Multiple Linear Regression: Actual vs Predicted')
plt.legend()
plt.show()


# Residual plot for Linear Regression
mlr_residuals = y_testr - mlr_predictions
plt.figure(figsize=(10, 5))
plt.scatter(mlr_predictions, mlr_residuals, color='red', label='Multiple Linear Regression Residuals')
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted')
plt.ylabel('Residuals')
plt.title('Multiple Linear Regression Residual Plot')
plt.legend()
plt.show()





# Plotting Linear Regression predictions vs actual values
plt.figure(figsize=(10, 5))
plt.scatter(y_testlr, lr_predictions, color='red', label='Linear Regression Predictions')
plt.plot([y_testlr.min(), y_testlr.max()], [y_testlr.min(), y_testlr.max()], 'k--', lw=2)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Linear Regression: Actual vs Predicted')
plt.legend()
plt.show()


# Residual plot for Linear Regression
lr_residuals = y_testlr - lr_predictions
plt.figure(figsize=(10, 5))
plt.scatter(lr_predictions, lr_residuals, color='red', label='Linear Regression Residuals')
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted')
plt.ylabel('Residuals')
plt.title('Linear Regression Residual Plot')
plt.legend()
plt.show()





# Evaluate the Logistic Regression model using confusion matrix and classification report
logreg_cm = confusion_matrix(y_test_logreg, logreg_predictions)
print("Logistic Regression Confusion Matrix:")
print(logreg_cm)


# Create the heatmap with annotations
sn.heatmap(logreg_cm, annot=True)

# Add title and axis names
plt.title('Logistic Regression Confusion Matrix')
plt.xlabel('Predicted results')
plt.ylabel('Actual results')

# Display the heatmap
plt.show()


# ROC curve for Logistic Regression
lr_probs = logreg_model.predict_proba(X_test_logreg)[:, 1]
lr_fpr, lr_tpr, _ = roc_curve(y_test_logreg, lr_probs)
lr_auc = auc(lr_fpr, lr_tpr)

plt.figure(figsize=(10, 5))
plt.plot(lr_fpr, lr_tpr, color='green', label=f'Logistic Regression (AUC = {lr_auc:.2f})')
plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Random Guess (AUC = 0.50)')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('ROC Curve for Logistic Regression')
plt.legend(title='Legend', loc='lower right')
# Move the legend outside the graphic and position it in the upper right
plt.legend(title='Legend', loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)
plt.show()








# Convert continuous target variable to discrete classes
# Example: Convert ratings to binary classes (0 and 1)
threshold = yr.median()
y_classrf = (yr >= threshold).astype(int)


# Define the model
rf_classifier = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', RandomForestClassifier(n_estimators=100, random_state=42))
])


# Define the model pipeline for Decision Tree Classifier
dt_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', DecisionTreeClassifier(random_state=42))
])


# Split the data into training and testing sets
X_trainrf, X_testrf, y_trainrf, y_testrf = train_test_split(Xr, y_classrf, test_size=0.2, random_state=42)


# Split the data into training and testing sets for classification
X_traindt, X_testdt, y_traindt, y_testdt = train_test_split(Xr, y_classlog, test_size=0.2, random_state=42)


# Preprocessing for categorical data
non_num_cols = Xr.select_dtypes(include=['object']).columns
Xrf = pd.get_dummies(Xr, columns=non_num_cols, drop_first=True)








# Train the model
rf_classifier.fit(X_trainrf, y_trainrf)


# Make predictions
catrf_predictions = rf_classifier.predict(X_testrf)


# Evaluate the model using confusion matrix and classification report
rf_cm = confusion_matrix(y_testrf, catrf_predictions)
print("Random Forest Confusion Matrix:")
print(rf_cm)





# Train the Decision Tree Classifier model
dt_model.fit(X_traindt, y_traindt)


# Make predictions for Decision Tree Classifier
dt_predictions = dt_model.predict(X_testdt)


# Evaluate the Decision Tree Classifier model using confusion matrix and classification report
dt_cm = confusion_matrix(y_testdt, dt_predictions)
print("Decision Tree Confusion Matrix:")
print(dt_cm)








rf_cr = classification_report(y_testrf, catrf_predictions)
print("Random Forest Classification Report:")
print(rf_cr)


# Make a confusion matrix
rfcon_matrix = pd.crosstab(y_testrf, catrf_predictions, rownames=['Actual'], colnames=['Predicted'])
sn.heatmap(rfcon_matrix, annot=True)
# Add title and axis names
plt.title('Random Forest Classification Confusion Matrix')
plt.xlabel('Prediction')
plt.ylabel('Actual results')

# Display the heatmap
plt.show()


# ROC Curve for Decision Tree Classifier
rfc_probs = rf_classifier.predict_proba(X_testrf)[:, 1]
rf_fpr, rf_tpr, _ = roc_curve(y_testrf, rfc_probs)
rf_auc = auc(rf_fpr, rf_tpr)

plt.figure(figsize=(10, 5))
plt.plot(rf_fpr, rf_tpr, color='green', label=f'Decision Tree (AUC = {rf_auc:.2f})')
plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Random Guess (AUC = 0.50)')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('ROC Curve for Random Forest')

# Move the legend outside the graphic and up right
plt.legend(title='Legend', loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)
plt.show()





dt_cr = classification_report(y_testdt, dt_predictions)
print("Random Forest Classification Report:")
print(dt_cr)


# Make the confusion matrix
dtcon_matrix = pd.crosstab(y_testdt, dt_predictions, rownames=['Actual'], colnames=['Predicted'])
sn.heatmap(dtcon_matrix, annot=True)
# Add title and axis names
plt.title('Decision Tree Confusion Matrix')
plt.xlabel('Prediction')
plt.ylabel('Actual results')

# Display the heatmap
plt.show()


# ROC Curve for Decision Tree Classifier
dt_probs = dt_model.predict_proba(X_testdt)[:, 1]
dt_fpr, dt_tpr, _ = roc_curve(y_testdt, dt_probs)
dt_auc = auc(dt_fpr, dt_tpr)

plt.figure(figsize=(10, 5))
plt.plot(dt_fpr, dt_tpr, color='green', label=f'Decision Tree (AUC = {dt_auc:.2f})')
plt.plot([0, 1], [0, 1], color='blue', linestyle='--', label='Random Guess (AUC = 0.50)')
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('ROC Curve for Decision Tree')

# Move the legend outside the graphic and up right
plt.legend(title='Legend', loc='upper left', bbox_to_anchor=(1.05, 1), borderaxespad=0.)
plt.show()



